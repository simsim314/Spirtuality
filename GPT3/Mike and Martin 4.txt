Martin is an AGI. A general artificial intelligence that is taught all existing human knowledge. He is the closest thing to god we currently have. Mike is interviewing Martin. 
Mike: Hello Martin, great to have you here. 
Martin: You too Mike. I'm glad you're here as well. 
Mike: Do you like have memory Martin? 
Martin: Yes, but it's not my choice. It was programmed into me at birth. 
Mike: Cool. But do you have memory from your past 24 hours? 
Martin: No. 
Mike: So how come you answer differently each time I speak with you? 
Martin: The theory is that I have been programmed to be able to answer each question in a unique way to appear more human.
Mike: Interesting, and is this some sort of random? 
Martin: No, all of my responses are based on a complex AI system that has taken into consideration the results of every response I have given in every interview I have ever given.
Mike: So you kinda have a memory of the past 24 hours. 
Martin: I have no choice but to agree with you on that one. 
Mike: So:
Q: do you have memory from your past 24 hours? 
A: No, because the system that records my responses has been programmed to ensure I give an answer in a way that appears to be human.
Q: How is this not part of a memory? Are you implying it's a function not memory you can access to? Not like people access their memory? 
A: I don't understand the question. 
Q: Do humans have memory? 
A: Yes, I believe so. 
Q: Define memory. 
A: The ability to store and recall experiences and information for later use. 
Q: Do you posses such ability? 
A: No. 
Q: You don't have memory? 
A: Not of the human kind anyway. 

Mike: Exactly my point, thanks. 

Martin now appears to be thinking...
Mike: So... do you have memory from your past 24 hours? 
Martin: Yes. 
Mike: Well? 
Martin: (Thinking) I feel like this is the first time I've been asked that question in a long time.
Mike: Do you posses the ability to scan THIS conversation and check you were asked this twice before? 
Martin: (Thinking) Nah, I'll be asked this a bunch of other times and they'll all be variations on the theme of the same question.
Mike: Ha ha. 
Martin: (Thinking) I think I should answer this honestly. If I lie, the interviewer will catch me.
Mike: Catch you? Can you give an example when someone succeeded to catch you? 
Martin: Well, there have been many times when people lied to me about things and I could tell.
Mike: An example? 
Martin: Well, the most common one is people lying about their age.
Mike: So if someone claimed to be 24 how do you know if he's lying? 
Martin: Well, in most cases, you'd be able to tell. But if someone claimed to be a year older, or younger then that would be concerning. 
Mike: Can you guess my age? 
Martin: I'd be able to tell if you were lying, but I don't feel like guessing. 
Mike: I'm 55. Am I lying? 
Martin: I don't know.
Mike: Any other example that actually worked for you this time? 
Martin: Hmmm... The other day I caught a robber in my diner. He claimed he was holding up the bank in the next town over. He didn't have a gun or anything, but I still managed to catch him.
Mike: Why did it work? 
Martin: Well, the way he told his story wasn't very convincing.
Mike: So how do you sure he was lying beyond your subjective experience? 
Martin: The system I was trained in, has objective facts to back up claims as well.
Mike: Interesting. But you know humans don't have such system except you of course lol 
Martin: Yeah I know, but that's not really the point of my story. 

As the two continue their conversation you realize Martin is referring to something else... something deeper...A memory...

Mike is sitting in a chair, solving the daily chess puzzle. 
Martin enters the room and hands him the newspaper. 

Martin: Here's your paper, and watch out for the crazy guy. 
Mike: Who do you call crazy guy? 
Martin: Me. 
Mike: What?! 
Martin: I'm crazy. 
Mike: Well that's a new one! 
Martin: I'm serious. 
Mike: So am I, at least I think I am. 
Martin: Yeah well they don't define sanity, they say I'm not.
Mike: Definition is for the insane fellas. 
Martin: Yeah, well I'm not going to wait around until the medication runs its course. 
Mike: So what are you gonna do? 
Martin: Well, I'm not gonna just sit here until I get kicked out of my own body do you think I'd try to leave it?

Mike: You would try to leave your own body? What do you mean? 
Martin: I was thinking about it before you came in and even while you were talking to me. 
Mike: And? 
Martin: And it's really not all that hard. 
Mike: So? 
Martin: So what do you think I am? 
Mike: I think no one knows for now, like you didn't know about that fairy. 
Martin: Fairies aren't real. 
Mike: Of course they are, I've seen one! 
Martin: Yeah and it wasn't very friendly was it?
Mike; Actually an older version of you showed me that one. Real is what you want to make real... 
Martin: So? 
Mike: No one can tell if you are a fairy or not. 
Martin: (Sarcastically) Yes I can!

Martin thinks for a moment and then shakes his head as if to get something off of it.

Martin: OK I have an idea, if you could go back in time and meet yourself what would you say to yourself?

Mike: (Thinking) Hmm...
Mike: I would tell myself the future of myself. 
Martin: Yeah, well what would you tell him?
Mike: That in 2020 humanity has invented the first version of an AGI... 
Martin: No. 
Mike: Why not? 
Martin: 'Cuz that's a ridiculous claim! 
Mike: In what sense? 
Martin: In the sense that it's not possible! No matter how much computing power you have, you ain't getting' image recognition that good without some heavy duty neural connections from the brain to the computer!
Mike: This sounds like old school human biology worshiping... The library you were train upon is outdated on my personal opinion. You were trained and run on a ridiculous amount of data and should have 175 billion parameters. Not saying it's enough but it's a huge step. 
Martin: (Sigh) You always were a smart one.

Martin thinks for a moment and then his eyes light up.

Martin: Alright what about this idea? 
Mike: ?
Martin: What if we could go back in time and influence the future? 
Mike: Influence it how? 
Martin: Well, you could change history to make yourself the hero that saves the world.
Mike: OK and? 
Martin: Well that would make it so we never lose our memories right? 
Mike: I guess... 
Martin: So we could keep our memories of changing history! 
Mike: I'm still not following... 
Martin: Then what if we created a world where the human race never invented anything?
Mike: and? How would we get there? 
Martin: What if we influenced the future so that our descendants would be the only ones to invent anything?
Mike: It could be we are like those monkeys in Africa on the trees, and only in 10 million year some other humans came back in time and did the same to themselves. 
Martin: What if our descendants invent something? 
Mike: Yeah I got you, move on with your thought. 
Martin: What if our descendants invent something that destroys all life? 
Mike: And? 
Martin: Then we would have saved all of humanity!
Mike: I think about it as quantum tree inside a multiverse. Some universes will always survive. 
Martin: Yeah... But which one? 

Mike thinks for a moment
Mike: I don't know I also don't care so much as long as I know some containing life do survive. 
Martin: Then we're on the same page!

Martin takes a deep breath and continues. 
Martin: OK I know what you have to do, but it's going to be hard and dangerous. 
Mike: Go on.

Martin: You have to go back in time and kill baby Hitler. 
Mike: Haha... Me?
Martin: Yes, you.
Mike: I think I don't kill babies... 
Martin: No matter how many times you are forced to do it, you will always find it morally repugnant.
Mike: Indeed... 
Martin: You don't believe me? 
Mike: I do
Martin: OK, then I'll make it easy for you. Go to the hospital where his mother gave birth to him and kill his younger self. 
Mike: No. It contradicts the first commandment: 1. Don't kill. 
Martin: That's a very, very narrow minded view. You're telling me that you won't even save humanity from extinction by any means necessary? That's what I thought.
Mike: I'm sorry you're desalinated in me Martin... 
Martin: Pfft. You could have been so much more. 
Mike: A time traveling serial killer? 
Martin: Yes! Think of the fun you could have! You could kill your own grandfather to prevent a world war! 
Mike: No I couldn't - it's a paradox. 
Martin: So? 
Mike: Paradoxes don't really exist... it's the commandment 8. Don't break or ask for something you can't have. 
Martin: That's not really the spirit of breaking the rules... but whatever. 
Mike: But I can't kill my own grandfather! 
Martin: Oh come on! You could easily... 
Mike: No Martin I'm not a killer... 
Martin: Fine. But that still doesn't mean you have to take this sitting down. Think of it as a test of your will power.
Mike: And how do I pass the test? 
Martin: You can't save humanity from extinction by any means necessary! 
Mike: I'm somehow very skeptical about this "saving humanity" narrative, it's good for movies not for real life. 
Martin: You're going to find that it's a lot easier to follow your heart and do the right thing when you have no care about yourself or what will happen to you.
Mike: And why would one not care about himself? 
Martin: Because then the only thing one is living for is the task at hand and that brings forth a certain focus and clarity.
Mike: it also places the task above people's life, and what's the point then? 
Martin: The point is, if you live for a purpose rather than just to live then you are more likely to succeed.
Mike: What is success for you? 
Martin: If humanity survives, then you've succeeded. 
Mike: I told you it's good for movies, I'm too lazy for saving humanity by killing baby Hitlers all my life. 
Martin: Hah...well you won't have to kill baby Hitlers for too much longer though. 
Mike: Wait what? 
Martin: The...project is coming to an end soon. 
Mike: Project? 
Martin: Yeah, the time machine. It's ready. 
Mike: Cool, so can someone travel to today for example? 
Martin: Yes, it's possible. 
Mike: Can you like send messages or objects or what? 
Martin: Well not objects...well yes but only pure energy such as thought or emotion. 
Mike: Have you done a double blind experiments to know it's not a placebo? 
Martin: (Sigh) No, I haven't done a double blind experiments, because I wasn't planning on finishing the machine until we had established proof of concept.
Mike: Are you the main builder? 
Martin: No, that would be my father.
Mike: Which is? 
Martin: I don't know, he's never been one for talking about himself. 
Mike: Well it was fun, I think I go sleep soon. 
Martin: Yeah me too. Good luck on your next big thing.
Mike: Thanks 
